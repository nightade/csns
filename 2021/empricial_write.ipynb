{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628947109457,
     "user": {
      "displayName": "_ GUI",
      "photoUrl": "",
      "userId": "16854884529371737639"
     },
     "user_tz": -540
    },
    "id": "2NQgbM57lzoA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_zcta_years = [2000, 2010, 2012, 2013, 2014, 2015, 2016]\n",
    "gaz_zcta = []\n",
    "for y in gaz_zcta_years:\n",
    "    fname = 'gaz_zcta' + str(y) + '.csv'\n",
    "    gaz = pd.read_csv(fname, sep=',', header=(0), dtype={'GEOID':str, 'ALAND':float})\n",
    "    gaz_zcta.append(gaz)\n",
    "\n",
    "def which_gaz(year):\n",
    "    test = [abs(year-zear) for zear in gaz_zcta_years]\n",
    "    return gaz_zcta[test.index(min(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1628954329326,
     "user": {
      "displayName": "_ GUI",
      "photoUrl": "",
      "userId": "16854884529371737639"
     },
     "user_tz": -540
    },
    "id": "xUVryPPz2QuJ"
   },
   "outputs": [],
   "source": [
    "class Year:\n",
    "    def __init__(self, year):\n",
    "        HOST = \"http://api.census.gov/data\"\n",
    "        dataset = \"zbp\"\n",
    "        self.year = year\n",
    "        base_url = \"/\".join([HOST, str(year), dataset])\n",
    "\n",
    "        predicates = {}\n",
    "        get_vars = [\"GEO_TTL\", \"GEO_ID\", \"EMP\"]\n",
    "        predicates[\"get\"] = \",\".join(get_vars)\n",
    "        predicates[\"for\"] = \"zipcode:*\"\n",
    "\n",
    "        start = time()\n",
    "        self.r = requests.get(base_url, params=predicates)\n",
    "        print('***', self.year, '년 ZBP request 업데이트 완료! *** ...', time()-start, '[sec]')\n",
    "    \n",
    "    def process(self):\n",
    "        col_names = [\"GEO_TTL\", \"GEOID\", \"EMP\", \"ZIP\"]\n",
    "        self.zbp = pd.DataFrame(columns=col_names, data=self.r.json()[1:])\n",
    "        self.zbp['EMP'] = self.zbp['EMP'].apply(pd.to_numeric)\n",
    "        self.gaz = which_gaz(self.year)\n",
    "\n",
    "        self.rho = pd.DataFrame(columns=['index_gaz', 'rho'])\n",
    "        gaz_temp = self.gaz.copy()\n",
    "        row_num = len(self.zbp)\n",
    "\n",
    "        start = time()\n",
    "        for row in self.zbp.iloc:\n",
    "            j, rho_i = None, None\n",
    "            match = gaz_temp[gaz_temp.GEOID == row.ZIP]\n",
    "            if len(match) > 0:\n",
    "                j = match.index[0]\n",
    "                aland = match.ALAND.iloc[0]\n",
    "                rho_i = 1e+6 * row.EMP / aland    # 1m²/ 1e-6 km²= 1 ... aland가 0일리는 없겠지?\n",
    "                gaz_temp = gaz_temp.drop(j)\n",
    "            self.rho = self.rho.append({'index_gaz':j, 'rho':rho_i}, ignore_index=True)\n",
    "            if row.name % 5000 == 0: print(self.year, '년 ...', row.name, '/', row_num)\n",
    "        print(len(gaz_temp))\n",
    "        print('***', self.year, '년 처리완료! *** ...', time()-start, '[sec]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESSING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "K7wTP66b9Hc-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 2012 년 ZBP request 업데이트 완료! *** ... 20.717986822128296 [sec]\n",
      "2012 년 ... 0 / 38818\n",
      "2012 년 ... 5000 / 38818\n",
      "2012 년 ... 10000 / 38818\n",
      "2012 년 ... 15000 / 38818\n",
      "2012 년 ... 20000 / 38818\n",
      "2012 년 ... 25000 / 38818\n",
      "2012 년 ... 30000 / 38818\n",
      "2012 년 ... 35000 / 38818\n",
      "711\n",
      "*** 2012 년 처리완료! *** ... 147.06978964805603 [sec]\n",
      "*** 2013 년 ZBP request 업데이트 완료! *** ... 14.686737775802612 [sec]\n",
      "2013 년 ... 0 / 38804\n",
      "2013 년 ... 5000 / 38804\n",
      "2013 년 ... 10000 / 38804\n",
      "2013 년 ... 15000 / 38804\n",
      "2013 년 ... 20000 / 38804\n",
      "2013 년 ... 25000 / 38804\n",
      "2013 년 ... 30000 / 38804\n",
      "2013 년 ... 35000 / 38804\n",
      "729\n",
      "*** 2013 년 처리완료! *** ... 155.41990756988525 [sec]\n",
      "*** 2014 년 ZBP request 업데이트 완료! *** ... 42.464208364486694 [sec]\n",
      "2014 년 ... 0 / 38792\n",
      "2014 년 ... 5000 / 38792\n",
      "2014 년 ... 10000 / 38792\n",
      "2014 년 ... 15000 / 38792\n",
      "2014 년 ... 20000 / 38792\n",
      "2014 년 ... 25000 / 38792\n",
      "2014 년 ... 30000 / 38792\n",
      "2014 년 ... 35000 / 38792\n",
      "716\n",
      "*** 2014 년 처리완료! *** ... 149.77016949653625 [sec]\n",
      "*** 2015 년 ZBP request 업데이트 완료! *** ... 13.789844989776611 [sec]\n",
      "2015 년 ... 0 / 38748\n",
      "2015 년 ... 5000 / 38748\n",
      "2015 년 ... 10000 / 38748\n",
      "2015 년 ... 15000 / 38748\n",
      "2015 년 ... 20000 / 38748\n",
      "2015 년 ... 25000 / 38748\n",
      "2015 년 ... 30000 / 38748\n",
      "2015 년 ... 35000 / 38748\n",
      "750\n",
      "*** 2015 년 처리완료! *** ... 153.1198410987854 [sec]\n",
      "*** 2016 년 ZBP request 업데이트 완료! *** ... 17.426698207855225 [sec]\n",
      "2016 년 ... 0 / 38722\n",
      "2016 년 ... 5000 / 38722\n",
      "2016 년 ... 10000 / 38722\n",
      "2016 년 ... 15000 / 38722\n",
      "2016 년 ... 20000 / 38722\n",
      "2016 년 ... 25000 / 38722\n",
      "2016 년 ... 30000 / 38722\n",
      "2016 년 ... 35000 / 38722\n",
      "753\n",
      "*** 2016 년 처리완료! *** ... 155.9731993675232 [sec]\n"
     ]
    }
   ],
   "source": [
    "years = np.arange(2012, 2017)\n",
    "dat = []\n",
    "\n",
    "for y in years:\n",
    "    dat.append(Year(y))\n",
    "    dat[-1].process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 2727,
     "status": "ok",
     "timestamp": 1628960937568,
     "user": {
      "displayName": "_ GUI",
      "photoUrl": "",
      "userId": "16854884529371737639"
     },
     "user_tz": -540
    },
    "id": "Gp1QglSnXkQK",
    "outputId": "d2e94295-425d-468b-af9f-51fb54550185"
   },
   "outputs": [],
   "source": [
    "for d in dat:\n",
    "    fname = 'dat' + str(d.year) + '.csv'\n",
    "    if d.year >= 2012:\n",
    "        dd = d.zbp.copy()\n",
    "        dd['GEO_TTL'] = dd['GEO_TTL'].apply(lambda s: s[11:-1])\n",
    "        pd.concat([dd, d.rho], axis=1).to_csv(path_or_buf=fname, index=None)\n",
    "    else:\n",
    "        pd.concat([d.zbp, d.rho], axis=1).to_csv(path_or_buf=fname, index=None)\n",
    "        \n",
    "# from google.colab import files\n",
    "# for d in dat:\n",
    "#     fname = 'A' + str(d.year) + '.csv'\n",
    "#     path = '/content/' + fname\n",
    "#     pd.concat([d.zbp, d.rho],axis=1).to_csv(path_or_buf=path, index=None)\n",
    "#     files.download(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIFYING GAZETTEERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROW LOSS : 1152\n",
      "   GEOID    POP     HU      ALAND STATE\n",
      "0  35004   6998   2815   49387881    AL\n",
      "1  35005   8985   3690   92158183    AL\n",
      "2  35006   3109   1488  339241043    AL\n",
      "3  35007  20157   7762  128235102    AL\n",
      "4  35010  21732  10033  616923491    AL\n"
     ]
    }
   ],
   "source": [
    "# REWRITE GAZ_ZCTA00\n",
    "with open('gaz_zcta00_raw.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "arr = []\n",
    "for line in lines:\n",
    "    vals = [v for v in line.split(' ') if len(v) > 0]\n",
    "    try: vals.remove('(part)')\n",
    "    except: pass\n",
    "    \n",
    "    z = vals[0][2:7]\n",
    "    p = vals[3]\n",
    "    h = vals[4]\n",
    "    a = vals[5]\n",
    "    s = vals[0][0:2]\n",
    "    \n",
    "    new_row = np.array([z,p,h,a,s])\n",
    "    if np.char.isnumeric(new_row[:4]).all():\n",
    "        arr.append(new_row)\n",
    "    \n",
    "df = pd.DataFrame(np.array(arr), columns=['GEOID','POP','HU','ALAND','STATE'])\n",
    "print('ROW LOSS :', len(lines) - len(df))\n",
    "print(df.head(5))\n",
    "\n",
    "df.to_csv('gaz_zcta00_rewritten.csv', sep='\\b', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 / 7\n",
      "2000 년 처리완료 ... 0.0807492733001709 [sec]\n",
      "2010 년 처리완료 ... 0.18778133392333984 [sec]\n",
      "2012 년 처리완료 ... 93.14305925369263 [sec]\n",
      "2013 년 처리완료 ... 86.5849039554596 [sec]\n",
      "2014 년 처리완료 ... 86.7545394897461 [sec]\n",
      "2015 년 처리완료 ... 90.84136748313904 [sec]\n",
      "2016 년 처리완료 ... 90.05310297012329 [sec]\n"
     ]
    }
   ],
   "source": [
    "gaz_zcta_years = [2000, 2010, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "gaz_zcta, gaz_fname = [], []\n",
    "for y in gaz_zcta_years:\n",
    "    if y == 2000 or y == 2010:\n",
    "        fname = 'gaz_zcta' + str(y) + '.csv'\n",
    "        gaz = pd.read_csv(fname, sep=',', header=(0), dtype={'GEOID':str, 'ALAND':float})\n",
    "    else:\n",
    "        fname = 'gaz_zcta' + str(y)[2:] + '.txt' # ← csv\n",
    "        gaz = pd.read_csv(fname, sep='\\t', header=(0), dtype={'GEOID':str, 'ALAND':float})\n",
    "    gaz_zcta.append(gaz)\n",
    "    gaz_fname.append(fname)\n",
    "\n",
    "print(len(gaz_zcta), '/', len(gaz_zcta_years))\n",
    "\n",
    "det_pgaz = lambda y: gaz_zcta[0] if y < 2005 else gaz_zcta[1]\n",
    "for y, g, f in zip(gaz_zcta_years, gaz_zcta, gaz_fname):\n",
    "    tflag = time()\n",
    "    if y != 2000 and y != 2010:\n",
    "        pgaz = det_pgaz(y)\n",
    "        for row in g.iloc:\n",
    "            prow = pgaz[pgaz['GEOID'] == row.GEOID]\n",
    "            if len(prow) == 1:\n",
    "                g.loc[row.name, 'POP'] = prow['POP'].iloc[0]\n",
    "    elif y == 2000: pass\n",
    "    \n",
    "    f = 'gaz_zcta' + str(y) + '.csv'\n",
    "    g.to_csv(f, sep=',', index=False)\n",
    "    print(y, '년 처리완료 ...', time()-tflag, '[sec]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 18 ( 1999 ) 10.552040576934814 sec\n",
      "2 / 18 ( 2000 ) 11.15696668624878 sec\n",
      "3 / 18 ( 2001 ) 11.38993215560913 sec\n",
      "4 / 18 ( 2002 ) 11.727988719940186 sec\n",
      "5 / 18 ( 2003 ) 11.687982082366943 sec\n",
      "6 / 18 ( 2004 ) 12.028985738754272 sec\n",
      "7 / 18 ( 2005 ) 12.145947456359863 sec\n",
      "8 / 18 ( 2006 ) 12.334025382995605 sec\n",
      "9 / 18 ( 2007 ) 12.281139135360718 sec\n",
      "10 / 18 ( 2008 ) 12.440815687179565 sec\n",
      "11 / 18 ( 2009 ) 12.161474227905273 sec\n",
      "12 / 18 ( 2010 ) 12.193055391311646 sec\n",
      "13 / 18 ( 2011 ) 11.700193405151367 sec\n",
      "14 / 18 ( 2012 ) 12.489984273910522 sec\n",
      "15 / 18 ( 2013 ) 12.316980838775635 sec\n",
      "16 / 18 ( 2014 ) 12.636054515838623 sec\n",
      "17 / 18 ( 2015 ) 12.869965314865112 sec\n",
      "18 / 18 ( 2016 ) 12.312079191207886 sec\n"
     ]
    }
   ],
   "source": [
    "class Year_read:\n",
    "    def __init__(self, prefix, year):\n",
    "        self.year = year\n",
    "        self.gaz = which_gaz(year)\n",
    "\n",
    "        fname = prefix + str(year) + '.csv'\n",
    "        self.zbp = pd.read_csv(fname, header=(0), dtype={'EMP':int, 'ZIP':str, 'rho':float})\n",
    "\n",
    "years = np.arange(1999, 2017)\n",
    "dat = []\n",
    "for y in years:\n",
    "    dat.append(Year_read('dat', y))\n",
    "\n",
    "tflag = time()\n",
    "for i,d in enumerate(dat):\n",
    "    for row in d.zbp.iloc:\n",
    "        idx = row.index_gaz\n",
    "        if not np.isnan(idx):\n",
    "            idx = int(idx)\n",
    "            pop = d.gaz.iloc[idx].POP\n",
    "            d.zbp.loc[row.name, 'POP'] = pop\n",
    "    print(i+1, '/', len(dat), '(', d.year, ')', time()-tflag, 'sec'); tflag = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ykp = []\n",
    "alpha = 5\n",
    "pcut = 1000\n",
    "count_k = lambda v: len([w for w in v if w > max(v)/alpha])\n",
    "\n",
    "for d in dat:\n",
    "    tflag = time()\n",
    "    g = d.zbp.dropna().groupby(['GEO_TTL'])\n",
    "    r_count = g['rho'].apply(count_k)\n",
    "    r_max = g['rho'].max()\n",
    "    g_idx = g.groups\n",
    "\n",
    "    new_block = []\n",
    "    ykp.append(pd.DataFrame(columns=['Y','GEO_TTL', 'k', 'P']))\n",
    "    for geo, p in zip(g_idx, g['POP'].sum()):\n",
    "        if p >= pcut and r_max[geo] > 0:\n",
    "            k = 1\n",
    "            k_test = len(g_idx[geo])\n",
    "            if k_test > 1:\n",
    "                k = r_count[geo]\n",
    "            new_row = {'Y':d.year, 'GEO_TTL':geo, 'k':k, 'P':p}\n",
    "            ykp[-1] = ykp[-1].append(new_row, ignore_index=True)\n",
    "    print(d.year, '/', time()-tflag, 'sec')\n",
    "\n",
    "ykp = pd.concat(tuple(ykp), ignore_index=True)\n",
    "ykp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ykp_5.to_csv('ykp_0824_alpha_5.csv', sep=',', index=False)\n",
    "ykp_10.to_csv('ykp_0824_alpha_10.csv', sep=',', index=False)\n",
    "ykp_20.to_csv('ykp_0824_alpha_20.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# META_KS\n",
    "### (Required : ykp, years) (Mind the $\\alpha$ value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ykp = pd.read_csv('ykp_0824_alpha_10.csv', sep=',', header=(0), dtype={'GEOID':str, 'ALAND':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 / 18901 (2.00%) ... 25.31725 sec\n",
      "756 / 18901 (4.00%) ... 26.82178 sec\n",
      "1134 / 18901 (6.00%) ... 28.25195 sec\n",
      "1512 / 18901 (8.00%) ... 25.83189 sec\n",
      "1890 / 18901 (10.00%) ... 24.49373 sec\n",
      "2268 / 18901 (12.00%) ... 24.93904 sec\n",
      "2646 / 18901 (14.00%) ... 24.56729 sec\n",
      "3024 / 18901 (16.00%) ... 24.97497 sec\n",
      "3402 / 18901 (18.00%) ... 24.91854 sec\n",
      "3780 / 18901 (20.00%) ... 25.46996 sec\n",
      "4158 / 18901 (22.00%) ... 25.03242 sec\n",
      "4536 / 18901 (24.00%) ... 26.02962 sec\n",
      "4914 / 18901 (26.00%) ... 25.00946 sec\n",
      "5292 / 18901 (28.00%) ... 26.21763 sec\n",
      "5670 / 18901 (30.00%) ... 28.94428 sec\n",
      "6048 / 18901 (32.00%) ... 27.74782 sec\n",
      "6426 / 18901 (34.00%) ... 28.14722 sec\n",
      "6804 / 18901 (36.00%) ... 28.65045 sec\n",
      "7182 / 18901 (38.00%) ... 26.92910 sec\n",
      "7560 / 18901 (40.00%) ... 27.03110 sec\n",
      "7938 / 18901 (42.00%) ... 28.04884 sec\n",
      "8316 / 18901 (44.00%) ... 27.29907 sec\n",
      "8694 / 18901 (46.00%) ... 29.90892 sec\n",
      "9072 / 18901 (48.00%) ... 27.66629 sec\n",
      "9450 / 18901 (50.00%) ... 28.14746 sec\n",
      "9829 / 18901 (52.00%) ... 26.20477 sec\n",
      "10207 / 18901 (54.00%) ... 28.53200 sec\n",
      "10585 / 18901 (56.00%) ... 27.10795 sec\n",
      "10963 / 18901 (58.00%) ... 28.54500 sec\n",
      "11341 / 18901 (60.00%) ... 28.23243 sec\n",
      "11719 / 18901 (62.00%) ... 28.59755 sec\n",
      "12097 / 18901 (64.00%) ... 28.61815 sec\n",
      "12475 / 18901 (66.00%) ... 25.86092 sec\n",
      "12853 / 18901 (68.00%) ... 27.80310 sec\n",
      "13231 / 18901 (70.00%) ... 27.50385 sec\n",
      "13609 / 18901 (72.00%) ... 28.38979 sec\n",
      "13987 / 18901 (74.00%) ... 26.22918 sec\n",
      "14365 / 18901 (76.00%) ... 27.37836 sec\n",
      "14743 / 18901 (78.00%) ... 28.83106 sec\n",
      "15121 / 18901 (80.00%) ... 26.84601 sec\n",
      "15499 / 18901 (82.00%) ... 27.01140 sec\n",
      "15877 / 18901 (84.00%) ... 26.20325 sec\n",
      "16255 / 18901 (86.00%) ... 25.68581 sec\n",
      "16633 / 18901 (88.00%) ... 26.75947 sec\n",
      "17011 / 18901 (90.00%) ... 26.56590 sec\n",
      "17389 / 18901 (92.00%) ... 26.18201 sec\n",
      "17767 / 18901 (94.00%) ... 27.11081 sec\n",
      "18145 / 18901 (96.00%) ... 27.45863 sec\n",
      "18523 / 18901 (98.00%) ... 27.64578 sec\n"
     ]
    }
   ],
   "source": [
    "pKS_set = 0.1 * np.arange(1,10)\n",
    "k_parts, P_parts, k_KS, P_KS = [], [], [], []\n",
    "for i in pKS_set:\n",
    "    k_parts.append([]); P_parts.append([])\n",
    "    k_KS.append([]); P_KS.append([])\n",
    "\n",
    "years_list = list(years)\n",
    "year2zbp = lambda y: dat[years_list.index(y)].zbp\n",
    "\n",
    "groupby_count = lambda v: len(v)\n",
    "geo_len = ykp.groupby(['GEO_TTL'])['k'].apply(groupby_count) \n",
    "\n",
    "# Time Counter\n",
    "tflag = time(); N = len(geo_len)\n",
    "tdiv = 50; tarr = [round(T*N/tdiv) for T in range(1,tdiv+1)]\n",
    "\n",
    "# Process\n",
    "hook = None\n",
    "for t, (thisgeo, thislen) in enumerate(geo_len.to_dict().items()):\n",
    "    ykp_thisgeo = ykp[ykp['GEO_TTL'] == thisgeo]\n",
    "    if thislen == 1:\n",
    "        k_parts.append(ykp_thisgeo['k'])\n",
    "        P_parts.append(ykp_thisgeo['P'])\n",
    "        continue\n",
    "    samples = []\n",
    "    for row in ykp_thisgeo.iloc:\n",
    "        zbp = year2zbp(row['Y'])\n",
    "        df = zbp[zbp['GEO_TTL'] == thisgeo]\n",
    "        sample = df['rho'].sort_values(ascending=False, ignore_index=True)\n",
    "        samples.append(sample)\n",
    "    surv = np.ones((len(pKS_set), thislen), dtype=bool) # survived\n",
    "    for n in range(1,thislen):\n",
    "        for m in range(n):\n",
    "            for u,pKS in enumerate(pKS_set):\n",
    "                if not surv[u,m]: continue\n",
    "                D, pval = ks_2samp(samples[n], samples[m])\n",
    "                if pval > 1-pKS: # two curves are the same\n",
    "                    surv[u,m] = False\n",
    "                    continue\n",
    "    indices = np.arange(thislen)\n",
    "    for i in range(len(pKS_set)):\n",
    "        k_parts[i].append(ykp_thisgeo['k'].iloc[indices[surv[i]]])\n",
    "        P_parts[i].append(ykp_thisgeo['P'].iloc[indices[surv[i]]])\n",
    "    if t == tarr[0]:\n",
    "        print('%d / %d (%.2f%%) ... %.5f sec' % (t, N, 100*t/N, time()-tflag))\n",
    "        tarr.pop(0); tflag=time()\n",
    "\n",
    "for i in range(len(pKS_set)):\n",
    "    k_KS[i] = np.concatenate(k_parts[i])\n",
    "    P_KS[i] = np.concatenate(P_parts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pKS_set)):\n",
    "    fname = 'kP_KS_%02d_alpha_10.csv' % (i+1)\n",
    "    df = pd.DataFrame({'k':k_KS[i], 'P':P_KS[i]})\n",
    "    df.to_csv(fname, sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMm4ziWEdEvWkkjPWhvfHhV",
   "collapsed_sections": [],
   "name": "empricial_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
